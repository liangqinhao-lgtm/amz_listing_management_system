"""å•†å“è¯¦æƒ…ç”ŸæˆæœåŠ¡"""
import json
import logging
import time
from typing import List, Tuple, Optional, Dict
from concurrent.futures import ThreadPoolExecutor, as_completed
from sqlalchemy.orm import Session

from infrastructure.llm import get_llm_service, LLMRequest
from infrastructure.db_pool import SessionLocal
from src.repositories.llm_product_detail_repository import LLMProductDetailRepository
from src.utils.data_cleaner import DataCleaner
from src.utils.prompt_manager import PromptManager

logger = logging.getLogger(__name__)

class ProductDetailGenerationService:
    """å•†å“è¯¦æƒ…ç”ŸæˆæœåŠ¡"""
    
    def __init__(
        self, 
        db: Session,
        batch_size: int = 50,
        max_retries: int = 3,
        thread_count: int = 4,
        max_input_length: int = 10000  # âœ… é»˜è®¤10000å­—ç¬¦
    ):
        self.db = db
        self.repository = LLMProductDetailRepository(db)
        self.llm_service = get_llm_service()
        self.prompt_manager = PromptManager()
        
        # é…ç½®å‚æ•°
        self.batch_size = batch_size
        self.max_retries = max_retries
        self.thread_count = thread_count
        self.max_input_length = max_input_length
        
        # ç»Ÿè®¡
        self.processed_count = 0
        self.failed_count = 0
    
    def process_single_sku(self, sku: str) -> Optional[Tuple]:
        """
        å¤„ç†å•ä¸ªSKU
        
        Returns:
            æˆåŠŸè¿”å›è¯¦æƒ…å…ƒç»„ï¼Œå¤±è´¥è¿”å›None
        """
        # ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        with SessionLocal() as thread_db:
            thread_repo = LLMProductDetailRepository(thread_db)
            
            try:
                # 1. è·å–åŸå§‹æ•°æ®
                raw_data = thread_repo.get_product_raw_data(sku)
                if not raw_data:
                    logger.warning(f"SKU {sku} æ— åŸå§‹æ•°æ®")
                    return None
                
                # 2. æ¸…æ´—æ•°æ®
                cleaned_data = DataCleaner.deep_clean(raw_data)
                
                # 3. æ™ºèƒ½æˆªæ–­ï¼ˆä¿æŒJSONå®Œæ•´æ€§ï¼‰
                user_prompt = DataCleaner.smart_truncate(
                    cleaned_data, 
                    max_json_length=self.max_input_length
                )
                
                # 4. è·å–Prompt
                system_prompt = self.prompt_manager.get_prompt('prod_detail_gen_amz')
                if not system_prompt:
                    logger.error(f"SKU {sku}: æ— æ³•åŠ è½½Prompt")
                    return None
                
                # 5. è°ƒç”¨LLMï¼ˆå¸¦é‡è¯•ï¼‰
                for attempt in range(self.max_retries):
                    try:
                        request = LLMRequest(
                            task_type='product_generation',
                            system_prompt=system_prompt,
                            user_prompt=user_prompt,
                            json_mode=True,
                            temperature=0.3
                        )
                        
                        response = self.llm_service.generate(request)
                        result = response.content
                        
                        # 6. éªŒè¯å¹¶è¡¥å…¨ç»“æœ
                        self._validate_and_fill_result(result)
                        
                        # 7. æ„é€ è¿”å›æ•°æ®
                        return (
                            sku,
                            result.get('äº§å“åç§°', ''),
                            result.get('äº§å“å–ç‚¹ 1', ''),
                            result.get('äº§å“å–ç‚¹ 2', ''),
                            result.get('äº§å“å–ç‚¹ 3', ''),
                            result.get('äº§å“å–ç‚¹ 4', ''),
                            result.get('äº§å“å–ç‚¹ 5', ''),
                            result.get('äº§å“æè¿°', ''),
                            f'llm_service_{response.provider}',
                            json.dumps(result, ensure_ascii=False)
                        )
                        
                    except Exception as e:
                        if attempt < self.max_retries - 1:
                            logger.warning(f"SKU {sku} å°è¯•{attempt+1}å¤±è´¥: {e}")
                            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                        else:
                            logger.error(f"SKU {sku} å¤„ç†å¤±è´¥: {e}")
                            return None
                
            except Exception as e:
                logger.exception(f"SKU {sku} å¤„ç†å¼‚å¸¸: {e}")
                return None
    
    def _validate_and_fill_result(self, result: Dict):
        """éªŒè¯å¹¶è¡¥å…¨ç»“æœ"""
        required_keys = {
            'äº§å“åç§°', 'äº§å“æè¿°',
            'äº§å“å–ç‚¹ 1', 'äº§å“å–ç‚¹ 2', 'äº§å“å–ç‚¹ 3',
            'äº§å“å–ç‚¹ 4', 'äº§å“å–ç‚¹ 5'
        }
        
        for key in required_keys:
            result.setdefault(key, '')
    
    def process_batch(self, sku_list: List[str]) -> int:
        """
        æ‰¹é‡å¤„ç†SKU
        
        Returns:
            æˆåŠŸå¤„ç†çš„æ•°é‡
        """
        batch_results = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=self.thread_count) as executor:
            futures = {
                executor.submit(self.process_single_sku, sku): sku 
                for sku in sku_list
            }
            
            for future in as_completed(futures):
                try:
                    result = future.result()
                    if result:
                        batch_results.append(result)
                except Exception as e:
                    sku = futures[future]
                    logger.error(f"SKU {sku} çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸: {e}")
        
        # æ‰¹é‡ä¿å­˜
        saved_count = self.repository.batch_save_details(batch_results)
        
        # æ›´æ–°ç»Ÿè®¡
        self.processed_count += saved_count
        self.failed_count += len(sku_list) - saved_count
        
        return saved_count
    
    def process_all_skus(self):
        """å¤„ç†æ‰€æœ‰æœªå¤„ç†çš„SKU"""
        logger.info("ğŸš€ å¼€å§‹LLMå•†å“è¯¦æƒ…ç”Ÿæˆæµç¨‹...")
        
        # 1. è·å–å¾…å¤„ç†SKU
        all_skus = self.repository.get_unprocessed_skus()
        
        if not all_skus:
            logger.info("âœ… æ²¡æœ‰éœ€è¦å¤„ç†çš„SKU")
            print("âœ… æ²¡æœ‰éœ€è¦å¤„ç†çš„SKU")
            return
        
        total_skus = len(all_skus)
        num_batches = (total_skus + self.batch_size - 1) // self.batch_size
        
        logger.info(f"ğŸ“Š å¾…å¤„ç†SKUæ€»æ•°: {total_skus}")
        print(f"\nğŸ“Š å¾…å¤„ç†SKUæ€»æ•°: {total_skus}")
        print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        print(f"ğŸ§µ çº¿ç¨‹æ•°: {self.thread_count}")
        print(f"ğŸ“ æœ€å¤§è¾“å…¥é•¿åº¦: {self.max_input_length}å­—ç¬¦\n")
        
        # 2. åˆ†æ‰¹å¤„ç†
        for batch_idx in range(num_batches):
            start_idx = batch_idx * self.batch_size
            end_idx = min((batch_idx + 1) * self.batch_size, total_skus)
            batch_skus = all_skus[start_idx:end_idx]
            
            logger.info(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{num_batches}: {len(batch_skus)}ä¸ªSKU")
            print(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{num_batches}...")
            
            saved_count = self.process_batch(batch_skus)
            
            logger.info(f"âœ”ï¸ æ‰¹æ¬¡{batch_idx+1}å®Œæˆ: æˆåŠŸ{saved_count}ä¸ª")
            print(f"   âœ”ï¸ æˆåŠŸ: {saved_count}/{len(batch_skus)}")
            print(f"   ğŸ“ˆ æ€»è¿›åº¦: {self.processed_count}/{total_skus}\n")
            
            time.sleep(0.5)  # æ‰¹æ¬¡é—´éš”
        
        # 3. è¾“å‡ºæ€»ç»“
        print("\n" + "="*60)
        print("âœ… å¤„ç†å®Œæˆï¼")
        print("="*60)
        print(f"æˆåŠŸ: {self.processed_count}")
        print(f"å¤±è´¥: {self.failed_count}")
        print(f"æ€»è®¡: {total_skus}")
        print("="*60 + "\n")
        
        logger.info(f"ğŸ‰ å¤„ç†å®Œæˆ: {self.processed_count}æˆåŠŸ | {self.failed_count}å¤±è´¥")
